{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from pprint import pprint\n",
    "from decisiontree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = importfile('hw3_house_votes_84.csv', ',')\n",
    "housecategory = {}\n",
    "for i in house[0]:\n",
    "    housecategory[i] = 'categorical'\n",
    "housecategory[\"class\"] = 'class'\n",
    "housedata = np.array(house[1:]).astype(float)\n",
    "\n",
    "# print(len(housedata))\n",
    "# print(housecategory)\n",
    "\n",
    "#class in last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = importfile('hw3_wine.csv', '\\t')\n",
    "winecategory = {}\n",
    "for i in wine[0]:\n",
    "    winecategory[i] = 'numerical'\n",
    "winecategory[\"# class\"] = 'class'\n",
    "winedata = np.array(wine[1:]).astype(float)\n",
    "# winedata = np.array([[float(item) for item in onelist] for onelist in wine[1:]])\n",
    "\n",
    "# print(len(winedata))\n",
    "# print(winecategory)\n",
    "\n",
    "#class in first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = importfile('hw3_cancer.csv', '\\t')\n",
    "cancercategory = {}\n",
    "for i in cancer[0]:\n",
    "    cancercategory[i] = 'numerical'\n",
    "cancercategory[\"Class\"] = 'class'\n",
    "cancerdata = np.array(cancer[1:]).astype(float)\n",
    "\n",
    "#print(len(cancerdata))\n",
    "#print(cancercategory)\n",
    "\n",
    "#class in last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc = importfile('cmc.data', ',')\n",
    "cmccategory = {\"Wife's age\":\"numerical\",\"Wife's education\":\"categorical\",\n",
    "\"Husband's education\":\"categorical\",\"Number of children ever born\":\"numerical\",\n",
    "\"Wife's religion\":\"binary\",\"Wife's now working?\":\"binary\",\n",
    "\"Husband's occupation\":\"categorical\",\"Standard-of-living index\":\"categorical\",\n",
    "\"Media exposure\":\"binary\",\"Contraceptive method used\":\"class\"}\n",
    "cmcdata = np.array(cmc).astype(int)\n",
    "\n",
    "# print(len(cmcdata))\n",
    "# print(cmccategory)\n",
    "\n",
    "#class in last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartbestseperate(dataset, attributes:dict):\n",
    "    # dataset in is the dataset by row. \n",
    "    # attributes is the dictionary of attributes:type \n",
    "    # types: numerical, categorical, binary.\n",
    "    datasetbycolumn = dataset.T\n",
    "    classindex = list(attributes.values()).index(\"class\")\n",
    "    originalgini = gini(datasetbycolumn[classindex])\n",
    "    smallestgini = originalgini\n",
    "    thresholdvalue = -1\n",
    "\n",
    "    i = 0\n",
    "    bestattribute = {list(attributes.keys())[i]:attributes[list(attributes.keys())[i]]}\n",
    "    attributesinuse = list(attributes.keys())[1:] if (classindex == 0) else list(attributes.keys())[:classindex]\n",
    "    # datasetinuse = datasetbycolumn[1:] if (classindex == 0) else datasetbycolumn[:classindex]\n",
    "\n",
    "    for attribute in attributesinuse:\n",
    "        idx = i+1 if classindex == 0 else i\n",
    "\n",
    "        if attributes[attribute] == \"categorical\" or attributes[attribute] == \"binary\":\n",
    "            listofkeys = list(Counter(datasetbycolumn[idx]).keys())\n",
    "            listofcategory = [] # this is the list of categorical values.\n",
    "            \n",
    "            for key in listofkeys:\n",
    "                indexlist = [idex for idex, element in enumerate(datasetbycolumn[idx]) if element == key]\n",
    "                category = np.array(datasetbycolumn[classindex][indexlist])\n",
    "                listofcategory.append(category)\n",
    "\n",
    "            currentgini = 0\n",
    "\n",
    "            for ctgry in listofcategory:\n",
    "                a = len(ctgry)/len(datasetbycolumn[idx]) # This is probability\n",
    "                currentgini += a * gini(ctgry)\n",
    "\n",
    "            if currentgini < smallestgini:\n",
    "                smallestgini = currentgini\n",
    "                bestattribute = {attribute:attributes[attribute]}\n",
    "            \n",
    "        elif attributes[attribute] == \"numerical\":\n",
    "            datasetsort = datasetbycolumn.T[datasetbycolumn.T[:,idx].argsort(kind='quicksort')].T\n",
    "            currentthreshold = (datasetsort[idx][1]+datasetsort[idx][0])/2\n",
    "            k = 1\n",
    "            while k < len(datasetsort.T):\n",
    "                currentthreshold = (datasetsort[idx][k]+datasetsort[idx][k-1])/2\n",
    "                listofcategory = [datasetsort[classindex][:k],datasetsort[classindex][k:]]\n",
    "                currentgini = 0\n",
    "\n",
    "                for ctgry in listofcategory:\n",
    "                    a = len(ctgry)/len(datasetbycolumn[idx]) # This is probability\n",
    "                    currentgini += a * gini(ctgry)\n",
    "\n",
    "                if currentgini < smallestgini:\n",
    "                    smallestgini = currentgini\n",
    "                    thresholdvalue = currentthreshold\n",
    "                    bestattribute = {attribute:attributes[attribute]}    \n",
    "                k += 1\n",
    "        i += 1\n",
    "\n",
    "    # set first attribution dictionary {key:type} to the best attributes.\n",
    "    return bestattribute, thresholdvalue, smallestgini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3bestseperate(dataset, attributes:dict):\n",
    "    # dataset in is the dataset by row. \n",
    "    # attributes is the dictionary of attributes:type \n",
    "    # types: numerical, categorical, binary.\n",
    "    datasetbycolumn = dataset.T\n",
    "    classindex = list(attributes.values()).index(\"class\")\n",
    "    originalentrophy = entropy(datasetbycolumn[classindex])\n",
    "    smallestentrophy = originalentrophy\n",
    "    thresholdvalue = -1\n",
    "\n",
    "    i = 0\n",
    "    bestattribute = {list(attributes.keys())[i]:attributes[list(attributes.keys())[i]]}\n",
    "    attributesinuse = list(attributes.keys())[1:] if (classindex == 0) else list(attributes.keys())[:classindex]\n",
    "    # datasetinuse = datasetbycolumn[1:] if (classindex == 0) else datasetbycolumn[:classindex]\n",
    "\n",
    "    for attribute in attributesinuse:\n",
    "        idx = i+1 if classindex == 0 else i\n",
    "\n",
    "        if attributes[attribute] == \"categorical\" or attributes[attribute] == \"binary\":\n",
    "            listofkeys = list(Counter(datasetbycolumn[idx]).keys())\n",
    "            listofcategory = [] # this is the list of categorical values.\n",
    "            \n",
    "            for key in listofkeys:\n",
    "                indexlist = [idex for idex, element in enumerate(datasetbycolumn[idx]) if element == key]\n",
    "                category = np.array(datasetbycolumn[classindex][indexlist])\n",
    "                listofcategory.append(category)\n",
    "\n",
    "            entropynow = 0\n",
    "\n",
    "            for ctgry in listofcategory:\n",
    "                a = len(ctgry)/len(datasetbycolumn[idx]) # This is probability\n",
    "                entropynow += a * entropy(ctgry)\n",
    "\n",
    "            if entropynow < smallestentrophy:\n",
    "                smallestentrophy = entropynow\n",
    "                bestattribute = {attribute:attributes[attribute]}\n",
    "            \n",
    "        elif attributes[attribute] == \"numerical\":\n",
    "            datasetsort = datasetbycolumn.T[datasetbycolumn.T[:,idx].argsort(kind='quicksort')].T\n",
    "            currentthreshold = (datasetsort[idx][1]+datasetsort[idx][0])/2\n",
    "            k = 1\n",
    "            while k < len(datasetsort.T):\n",
    "                currentthreshold = (datasetsort[idx][k]+datasetsort[idx][k-1])/2\n",
    "                listofcategory = [datasetsort[classindex][:k],datasetsort[classindex][k:]]\n",
    "                entropynow = 0\n",
    "\n",
    "                for ctgry in listofcategory:\n",
    "                    a = len(ctgry)/len(datasetbycolumn[idx]) # This is probability\n",
    "                    entropynow += a * entropy(ctgry)\n",
    "\n",
    "                if entropynow < smallestentrophy:\n",
    "                    smallestentrophy = entropynow\n",
    "                    thresholdvalue = currentthreshold\n",
    "                    bestattribute = {attribute:attributes[attribute]}    \n",
    "                k += 1\n",
    "        i += 1\n",
    "\n",
    "    gain = originalentrophy-smallestentrophy\n",
    "    # set first attribution dictionary {key:type} to the best attributes.\n",
    "    return bestattribute, thresholdvalue, gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropbyindex(data, category, listindex):\n",
    "    newdata = np.delete(data.T, listindex,0).T\n",
    "    keytoremove = [list(category.keys())[i] for i in listindex]\n",
    "    newcategory = category.copy()\n",
    "    [newcategory.pop(key) for key in keytoremove]\n",
    "    return newdata, newcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "def decisiontree(dataset: np.array, dictattributes: dict, algortype: str ='id3'):\n",
    "    datasetcopy = np.copy(dataset).T # dataset copy is by colomn. \n",
    "    dictattricopy = dictattributes.copy()\n",
    "    classindex = list(dictattricopy.values()).index(\"class\")\n",
    "\n",
    "    def processbest(algor):\n",
    "        if algor == \"cart\" or algor == \"gini\":\n",
    "            return cartbestseperate(datasetcopy.T, dictattricopy)\n",
    "        else: # algor == \"id3\" or algor == \"infogain\"\n",
    "            return id3bestseperate(datasetcopy.T, dictattricopy)\n",
    "\n",
    "    node = Treenode(label=-1,type=\"decision\")\n",
    "\n",
    "    node.majority = majority(datasetcopy[classindex])\n",
    "\n",
    "    if same(datasetcopy[classindex]):\n",
    "        node.type = \"leaf\"\n",
    "        node.label = datasetcopy[classindex][0]\n",
    "        return node\n",
    "    \n",
    "    if len(dictattricopy) == 0:\n",
    "        node.type = \"leaf\"\n",
    "        node.label = majority(datasetcopy[classindex])\n",
    "        return node\n",
    "\n",
    "    bestattributedict,thresholdval = processbest(algortype)[:2]\n",
    "    bestattributename = list(bestattributedict.keys())[0]\n",
    "    bestattributetype = bestattributedict[bestattributename]\n",
    "    node.testattributedict = bestattributedict\n",
    "    node.datatype = bestattributetype\n",
    "    node.testattribute = bestattributename\n",
    "    node.threshold = thresholdval\n",
    "    bindex = list(dictattricopy.keys()).index(list(bestattributedict.keys())[0])\n",
    "\n",
    "    subdatalists = []\n",
    "    if bestattributetype == \"numerical\":\n",
    "        sortedcopy = datasetcopy.T[datasetcopy.T[:,bindex].argsort(kind='quicksort')].T\n",
    "        splitindex = 0\n",
    "        for numericalvalue in sortedcopy[bindex]:\n",
    "            if numericalvalue > thresholdval:\n",
    "                break\n",
    "            else:\n",
    "                splitindex += 1\n",
    "        subdatalistraw = [sortedcopy.T[:splitindex].T,sortedcopy.T[splitindex:].T]\n",
    "        for subdata in subdatalistraw:\n",
    "            subdatav = np.delete(subdata,bindex,0)\n",
    "            subdatalists.append(subdatav.T)\n",
    "    else:\n",
    "        bigv = list(Counter(datasetcopy[bindex]).keys()) # this is the all the categories of the test attribute left.\n",
    "    \n",
    "        for smallv in bigv:\n",
    "            index = [idx for idx, element in enumerate(datasetcopy[bindex]) if element == smallv]\n",
    "            subdatav = np.array(datasetcopy.T[index]).T\n",
    "            subdatav = np.delete(subdatav,bindex,0)  # I delete the column I already used using bindex as reference. \n",
    "            # Then, later, pop the same index from list attribute.\n",
    "            subdatalists.append(subdatav.T) # list of nparrays of target/label/categories.\n",
    "\n",
    "    dictattricopy.pop(bestattributename)\n",
    "    \n",
    "    edge = {}\n",
    "    sdindex = 0\n",
    "    for subvdata in subdatalists:\n",
    "        if subvdata.size == 0:\n",
    "            node.type = \"leaf\"\n",
    "            node.label = node.majority\n",
    "            node.threshold = thresholdval\n",
    "            return node\n",
    "\n",
    "        subtree = decisiontree(subvdata, dictattricopy, algortype)\n",
    "        if bestattributetype == 'numerical':\n",
    "            attributevalue = \"<=\" if sdindex == 0 else \">\"\n",
    "        else:\n",
    "            attributevalue = bigv[sdindex]\n",
    "\n",
    "        edge[attributevalue] = subtree\n",
    "        sdindex += 1\n",
    "\n",
    "    node.edge = edge\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisiontreenew(dataset: np.array, dictattributes: dict, algortype: str ='id3'):\n",
    "    datasetcopy = np.copy(dataset).T # dataset copy is by colomn. \n",
    "    dictattricopy = dictattributes.copy()\n",
    "    classindex = list(dictattricopy.values()).index(\"class\")\n",
    "\n",
    "    def processbest(algor):\n",
    "        if algor == \"cart\" or algor == \"gini\":\n",
    "            return cartbestseperate(datasetcopy.T, dictattricopy)\n",
    "        else: # algor == \"id3\" or algor == \"infogain\"\n",
    "            return id3bestseperate(datasetcopy.T, dictattricopy)\n",
    "\n",
    "    node = Treenode(label=-1,type=\"decision\")\n",
    "    # currentdepth = node.depth\n",
    "\n",
    "    node.majority = majority(datasetcopy[classindex])\n",
    "\n",
    "    if same(datasetcopy[classindex]):\n",
    "        node.type = \"leaf\"\n",
    "        node.label = datasetcopy[classindex][0]\n",
    "        return node\n",
    "    \n",
    "    if len(dictattricopy) == 0:\n",
    "        node.type = \"leaf\"\n",
    "        node.label = majority(datasetcopy[classindex])\n",
    "        return node\n",
    "\n",
    "    bestattributedict,thresholdval = processbest(algortype)[:2]\n",
    "    bestattributename = list(bestattributedict.keys())[0]\n",
    "    bestattributetype = bestattributedict[bestattributename]\n",
    "    node.testattributedict = bestattributedict\n",
    "    node.datatype = bestattributetype\n",
    "    node.testattribute = bestattributename\n",
    "    node.threshold = thresholdval\n",
    "    bindex = list(dictattricopy.keys()).index(list(bestattributedict.keys())[0])\n",
    "\n",
    "    subdatalists = []\n",
    "    if bestattributetype == \"numerical\":\n",
    "        sortedcopy = datasetcopy.T[datasetcopy.T[:,bindex].argsort(kind='quicksort')].T\n",
    "        splitindex = 0\n",
    "        for numericalvalue in sortedcopy[bindex]:\n",
    "            if numericalvalue > thresholdval:\n",
    "                break\n",
    "            else:\n",
    "                splitindex += 1\n",
    "        subdatalistraw = [sortedcopy.T[:splitindex].T,sortedcopy.T[splitindex:].T]\n",
    "        for subdata in subdatalistraw:\n",
    "            subdatav = np.delete(subdata,bindex,0)\n",
    "            subdatalists.append(subdatav.T)\n",
    "    else:\n",
    "        bigv = list(Counter(datasetcopy[bindex]).keys()) # this is the all the categories of the test attribute left.\n",
    "    \n",
    "        for smallv in bigv:\n",
    "            index = [idx for idx, element in enumerate(datasetcopy[bindex]) if element == smallv]\n",
    "            subdatav = np.array(datasetcopy.T[index]).T\n",
    "            subdatav = np.delete(subdatav,bindex,0)  # I delete the column I already used using bindex as reference. \n",
    "            # Then, later, pop the same index from list attribute.\n",
    "            subdatalists.append(subdatav.T) # list of nparrays of target/label/categories.\n",
    "\n",
    "    dictattricopy.pop(bestattributename)\n",
    "    \n",
    "    edge = {}\n",
    "    sdindex = 0\n",
    "    for subvdata in subdatalists:\n",
    "        if subvdata.size == 0:\n",
    "            node.type = \"leaf\"\n",
    "            node.label = node.majority\n",
    "            node.threshold = thresholdval\n",
    "            return node\n",
    "\n",
    "        subtree = decisiontree(subvdata, dictattricopy, algortype)\n",
    "        # subtree.depth = currentdepth + 1\n",
    "        subtree.parent = node\n",
    "        if bestattributetype == 'numerical':\n",
    "            attributevalue = \"<=\" if sdindex == 0 else \">\"\n",
    "        else:\n",
    "            attributevalue = bigv[sdindex]\n",
    "\n",
    "        edge[attributevalue] = subtree\n",
    "        sdindex += 1\n",
    "\n",
    "    node.edge = edge\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train(data, rand=691):\n",
    "    train, test = sklearn.model_selection.train_test_split(data, train_size=0.8, test_size=0.2, random_state=rand, shuffle=True)\n",
    "    return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using tree\n",
    "\n",
    "def prediction(tree: Treenode, instance, dictattricopy): # note that the instance if by row. (I formerly used by column)\n",
    "    predict = tree.majority\n",
    "    classindex = list(dictattricopy.values()).index(\"class\")\n",
    "    correct = instance[classindex]\n",
    "    if tree.type == 'leaf':\n",
    "        predict = tree.label\n",
    "        return predict==correct, predict, correct\n",
    "\n",
    "    testindex = list(dictattricopy.keys()).index(tree.testattribute)\n",
    "    \n",
    "    if tree.datatype == \"numerical\":\n",
    "        if instance[testindex] <= tree.threshold:\n",
    "            nexttree = tree.edge['<=']\n",
    "        else:\n",
    "            nexttree = tree.edge['>']\n",
    "    else:\n",
    "        if instance[testindex] not in tree.edge:\n",
    "            return predict==correct, predict, correct\n",
    "            \n",
    "        nexttree = tree.edge[instance[testindex]]\n",
    "\n",
    "    return prediction(nexttree, instance, dictattricopy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "removeindex= [3,4,5,6]\n",
    "d1,c1=dropbyindex(cancerdata,cancercategory,removeindex)\n",
    "\n",
    "train1, test1 = split_test_train(d1)\n",
    "traintree = decisiontreenew(train1,c1,'gini')\n",
    "print(traintree.edge['>'].edge['>'].parent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9357142857142857\n"
     ]
    }
   ],
   "source": [
    "correctcount = 0\n",
    "# print(c1)\n",
    "for instance in test1:\n",
    "    if prediction(traintree,instance,c1)[0]:\n",
    "        correctcount+=1\n",
    "\n",
    "accrate = correctcount/len(test1)\n",
    "print(accrate)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
